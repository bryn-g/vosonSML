% Generated by roxygen2: do not edit by hand
% Please edit documentation in R/create_network.semantic.twitter.R
\name{create_network.semantic.twitter}
\alias{create_network.semantic.twitter}
\title{Create twitter semantic network}
\usage{
\method{create_network}{semantic.twitter}(
  datasource,
  type,
  rm_nodes = NULL,
  stopwords = TRUE,
  stw_lang = "en",
  stw_src = "smart",
  incl_numbers = TRUE,
  incl_urls = FALSE,
  top_words = 5,
  top_hashtags = 20,
  assoc = "limited",
  verbose = FALSE,
  ...
)
}
\arguments{
\item{datasource}{Collected social media data with \code{"datasource"} and \code{"twitter"} class names.}

\item{type}{Character string. Type of network to be created, set to \code{"semantic"}.}

\item{rm_nodes}{Character vector. Words or hashtags to remove from the semantic network. For example, 
this parameter could be used to remove the search term or hashtag that was used to collect the data by removing any
nodes with matching name. Effectively a custom stopwords list. Default is \code{NULL}.}

\item{stopwords}{Logical. Removes language stopwords from the tweet data. Default is \code{TRUE}.}

\item{stw_lang}{Character string. Language of stopwords to use. Refer to the \pkg{stopwords} package for
further information on supported languages. Default is \code{"en"} for english.}

\item{stw_src}{Character string. Source of stopwords list. Refer to the \pkg{stopwords} package for
further information on supported sources. Default is \code{"smart"}.}

\item{incl_numbers}{Logical. Include whole numerical tokens from the tweet text. For example, a year value
such as \code{2020} will be removed but not mixed values such as \code{G20}. Default is \code{TRUE}.}

\item{incl_urls}{Logical. Include twitter shortened URL tokens found in tweet text. Default is \code{FALSE}.}

\item{top_words}{Numeric integer. Specifies the percentage of most frequent words to include. For example,
\code{top_words = 20} means that the 20 percent most frequently occurring \code{words} will be included in the 
semantic network as nodes. A larger percentage will increase the number of nodes and therefore the size of graph. 
The default value is \code{5}, meaning the top 5 percent most frequent words are used.}

\item{top_hashtags}{Numeric integer. Specifies the percentage of most frequent \code{hashtags} to include. For 
example, \code{top_hashtags = 20} means that the 20 percent most frequently occurring hashtags will be included 
in the semantic network as nodes. The default value is \code{50}.}

\item{assoc}{Character string. Association of nodes. A value of \code{"limited"} includes only edges between
most frequently occurring hashtags and words. A value of \code{"full"} includes ties between most frequently
occurring hashtags and words, hashtags and hashtags, and also words and words. Default is \code{"limited"}.}

\item{verbose}{Logical. Output additional information about the network creation. Default is \code{FALSE}.}

\item{...}{Additional parameters passed to function. Not used in this method.}
}
\value{
Network as a named list of two dataframes containing \code{$nodes} and \code{$edges}.
}
\description{
Creates a semantic network from tweets returned from the twitter search query. Semantic networks 
describe the semantic relationships between concepts. In this network the concepts are significant words and 
hashtags extracted from the tweet text. Network edges are weighted and represent occurrence of words and
hashtags in the same tweets.

The creation of twitter semantic networks requires text processing and the tokenization of tweets. As such
this function requires the additional installation of the \pkg{tidyr} and \pkg{tidytext} packages to achieve
this.
}
\note{
The words and hashtags passed to the function in the \code{rm_nodes} parameter are removed
before word frequencies are calculated and are therefore excluded from top percentage of most frequent words
completely rather than simply filtered out of the final network.

The top percentage of frequently occurring hashtags \code{top_hashtags} and words \code{top_words} are calculated to 
a minimum frequency and all words that have an equal or greater frequency than the minimum are included in the 
network as nodes. For example, of unique hashtags of varying frequencies in a dataset the top 50% of total
frequency or most common hashtags may calculate to being the first 20 hashtags. The frequency of the 20th hashtag is
then used as the minimum and all hashtags of equal or greater frequency are included as part of the top 50%
most frequently occurring hashtags. So the number of top hashtags may end up being greater than 20 if there is more
than one hashtag that has frequency matching the minimum. The exception to this is if the minimum frequency is 1
and the \code{top_hashtags} is set to less than 100, in this case only the first 20 hashtags will be included.

Hashtags and words in the top percentages are included in the network as isolates if there are no instances of
them occurring in tweet text with other top percentage frequency words.
}
\examples{
\dontrun{
# twitter semantic network creation additionally requires the tidyr, tidytext and stopwords packages
# for working with text data
install.packages(c("tidyr", "tidytext", "stopwords"))

# create a twitter semantic network graph removing the hashtag '#auspol' and using the
# top 2\% frequently occurring words and 10\% most frequently occurring hashtags as nodes
semantic_net <- twitter_data \%>\% 
  create_network("semantic", rm_nodes = c("#auspol"), top_words = 2, top_hashtags = 10)

# network nodes and edges
# semantic_net$nodes
# semantic_net$edges
}

}
